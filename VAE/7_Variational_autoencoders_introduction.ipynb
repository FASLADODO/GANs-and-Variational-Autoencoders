{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Variational Autoencoders Introduction<hr>\n",
    "\n",
    "## Variational Autoencoder\n",
    "- Section outline\n",
    "- VAE is a neural network that learns to reproduce its input\n",
    "- Can map data to latent space\n",
    "- Can generate samples by first sampling from latent space\n",
    "- A neural network that learns to reproduce its input\n",
    "- Important feature: # hidden units < # inputs\n",
    "- Create a **bottleneck**: forces net to learn compact representation of data\n",
    "\n",
    "## Bottleneck\n",
    "- Suppose we can teach a neural net to reproduce its input\n",
    "- It *\"means\"* we have learned a much smaller *\"code\"* for the input: 784 -> 200 numbers\n",
    "- Out of the original 784 numbers, many of them were redundant\n",
    "- The *\"true\"* amount of information in the original data must be << 784 numbers\n",
    "- We call these 200 numbers the **\"latent variable representation\" with the letter \"z\"**\n",
    "\n",
    "## Variational\n",
    "- Refers to variational inference or variational Bayes\n",
    "- Fall into the realm of Bayesian machine learning\n",
    "- Could be an entire semester graduate course\n",
    "- One way to think of variational inference: it's an extension of expectation-maximization (EM)\n",
    "- Note: this information is just historical to give you the big picture, it's not required to understand variational autoencoders\n",
    "\n",
    "## Variational Inference\n",
    "- Expectation-maximization is used when we have a latent variable model, and we can't maximize p(X) directly \n",
    "- Example: Gaussian Mixture Model\n",
    "- EM gives us a point estimate of the parameters\n",
    "- i.e. it's frequentist\n",
    "- VI is Bayesian - we learn the distributions of the parameters instead\n",
    "\n",
    "## Summary\n",
    "- Some background on what elements make up the \"variational autoencoder\"\n",
    "![variational_autoencoders](../images/variational_autoencoders.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
