{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Implementation (part_2)<hr>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets('MNIST_data/', one_hot = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = mnist.train.images\n",
    "Y = mnist.train.labels\n",
    "\n",
    "\n",
    "st = None\n",
    "Normal = tf.contrib.distributions.Normal\n",
    "Bernoulli = tf.contrib.distributions.Bernoulli"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseLayer(object):\n",
    "    def __init__(self, M1, M2, f = tf.nn.relu):\n",
    "        self.W = tf.Variable(tf.random_normal(shape=(M1, M2)) * 2 / np.sqrt(M1))\n",
    "        self.b = tf.Variable(np.zeros(M2).astype(np.float32))\n",
    "        self.f = f\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return self.f(tf.matmul(X, self.W) + self.b)\n",
    "    \n",
    "\n",
    "class VariationalAutoencoder:\n",
    "    def __init__(self, D, hidden_layer_sizes):\n",
    "        # hidden_layer_sizes specifies the size of every layer\n",
    "        # in the encoder\n",
    "        # up to the final hidden layer Z\n",
    "        # the decoder will have the reverse shape\n",
    "        \n",
    "        # represents a batch of training data\n",
    "        self.X = tf.placeholder(tf.float32, shape=(None, D))\n",
    "        \n",
    "        # encoder\n",
    "        self.encoder_layers = []\n",
    "        M_in = D\n",
    "        for M_out in hidden_layer_sizes[:-1]:\n",
    "            h = DenseLayer(M_in, M_out)\n",
    "            self.encoder_layers.append(h)\n",
    "            M_in = M_out\n",
    "        \n",
    "        # for convenience, we'll refer to the final encoder size as M\n",
    "        # also the input to the decoder size\n",
    "        M = hidden_layer_sizes[-1]\n",
    "        \n",
    "        # the encoder's final layer output is unbounded\n",
    "        # so there is no activation function\n",
    "        # we also need 2 times as many units as specified by M_out\n",
    "        # since there needs be M_out means + M_out variances\n",
    "        h = DenseLayer(M_in, 2 * M, f = lambda x: x)\n",
    "        self.encoder_layers.append(h)\n",
    "        \n",
    "        # get the mean and variance / std dev of Z.\n",
    "        # note that the variance must be > 0\n",
    "        # we can get a sigma (standard dev) > 0 from an unbounded variable by\n",
    "        # passing it through the softplus function.\n",
    "        # add a small amount for smoothing\n",
    "        currunt_layer_value = self.X\n",
    "        for layer in self.encoder_layers:\n",
    "            currunt_layer_value = layer.forward(currunt_layer_value)\n",
    "        self.means = currunt_layer_value[:,:M]\n",
    "        self.stddev = tf.nn.softplus(currunt_layer_value[:,M:] + 1e-6)\n",
    "        \n",
    "        \n",
    "        # get a sample of Z\n",
    "        # we need to use a stochastic tensor\n",
    "        # in order for the errors to be backpropagated past this point\n",
    "        standard_normal = Normal(\n",
    "            loc=np.zeros(M, dtype=np.float32),\n",
    "            scale=np.ones(M, dtype=np.float32)\n",
    "        )\n",
    "        e = standard_normal.sample(tf.shape(self.means)[0])\n",
    "        self.Z = e * self.stddev + self.means\n",
    "        \n",
    "        # note: this also works because Tensorflow\n",
    "        # now does the \"magic\" for you \n",
    "        # n= Normal(\n",
    "        #   loc = self.means,\n",
    "        #   scale = self.stddev,\n",
    "        # )\n",
    "        # self.Z = n.sample()\n",
    "        \n",
    "        \n",
    "        \n",
    "        # decoder\n",
    "        self.decoder_layers = []\n",
    "        M_in = M\n",
    "        for M_out in reversed(hidden_layer_sizes[:-1]):\n",
    "            h = DenseLayer(M_in, M_out)\n",
    "            self.decoder_layers.append(h)\n",
    "            M_in = M_out\n",
    "        \n",
    "        # the decoder's final layer should technically go through a sigmoid\n",
    "        # so that the final output is a binary probability (e.g. Bernoulli)\n",
    "        # but Bernoulli accpets logits (pre-sigmoid) so we will take those\n",
    "        # so no activation function is needed at the final layer\n",
    "        h = DenseLayer(M_in, D, f = lambda x: x)\n",
    "        self.decoder_layers.append(h)\n",
    "        \n",
    "        # get the logits\n",
    "        currunt_layer_value = self.Z\n",
    "        for layer in self.decoder_layers:\n",
    "            currunt_layer_value = layer.forward(currunt_layer_value)\n",
    "        logits = currunt_layer_value\n",
    "        posterior_predictive_logits = logits # save for later\n",
    "        \n",
    "        # get the output\n",
    "        self.X_hat_distribution = Bernoulli(logits=logits)\n",
    "        \n",
    "        # take samples from X_hat\n",
    "        # we will call this the posterior predictive sample\n",
    "        self.posterior_predictive = self.X_hat_distribution.sample()\n",
    "        self.posterior_predictive_probs = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        \n",
    "        # take sample from a Z ~ N(0, 1)\n",
    "        # and put it through the decoder\n",
    "        # we will call this the prior predictive sample\n",
    "        standard_normal = Normal(\n",
    "            loc=np.zeros(M, dtype=np.float32),\n",
    "            scale=np.ones(M, dtype=np.float32)\n",
    "        )\n",
    "        \n",
    "        Z_std = standard_normal.sample(1)\n",
    "        currunt_layer_value = Z_std\n",
    "        for layer in self.decoder_layers:\n",
    "            currunt_layer_value = layer.forward(currunt_layer_value)\n",
    "        logits = currunt_layer_value\n",
    "        \n",
    "        prior_predictive_dist = Bernoulli(logits=logits)\n",
    "        self.prior_predictive = prior_predictive_dist.sample()\n",
    "        self.prior_predictive_probs = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        \n",
    "        # prior predictive from input\n",
    "        # only used for generating visualization\n",
    "        self.Z_input = tf.placeholder(tf.float32, shape=(None, M))\n",
    "        currunt_layer_value = self.Z_input\n",
    "        for layer in self.decoder_layers:\n",
    "            currunt_layer_value = layer.forward(currunt_layer_value)\n",
    "        logits = currunt_layer_value\n",
    "        self.prior_predictive_from_input_probs = tf.nn.sigmoid(logits)\n",
    "        \n",
    "        \n",
    "        # now build the cost\n",
    "        kl = -tf.log(self.stddev) + 0.5 * (self.stddev**2 + self.means**2) - 0.5\n",
    "        kl = tf.reduce_sum(kl, axis=1)\n",
    "        expected_log_likelihood = tf.reduce_sum(\n",
    "            self.X_hat_distribution.log_prob(self.X),1\n",
    "        )\n",
    "        \n",
    "        # equivalent\n",
    "        # expected_log_likelihood = -tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        #   labels = self.X,\n",
    "        #   logits = posterior_predictive_logits\n",
    "        # )\n",
    "        # expected_log_likelihood = -tf.reduce_sum(expected_log_likelihood, 1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.elbo = tf.reduce_sum(expected_log_likelihood - kl)\n",
    "        self.train_op = tf.train.RMSPropOptimizer(learning_rate=0.001).minimize(-self.elbo)\n",
    "        \n",
    "        # set up session and variables for later\n",
    "        self.init_op = tf.global_variables_initializer()\n",
    "        self.sess = tf.Session()\n",
    "        self.sess.run(self.init_op)\n",
    "        \n",
    "        \n",
    "    def fit(self, X, epochs = 30, batch_sz = 200):\n",
    "        costs = []\n",
    "        n_batches = len(X) // batch_sz\n",
    "        print(\"n_batches: \", n_batches)\n",
    "        for i in range(epochs):\n",
    "            print('epochs: ', i)\n",
    "            np.random.shuffle(X)\n",
    "            for j in range(n_batches):\n",
    "                batch = X[j*batch_sz:(j+1)*batch_sz]\n",
    "                _, c = self.sess.run([self.train_op, self.elbo], feed_dict = {self.X:batch})\n",
    "                c /= batch_sz\n",
    "                costs.append(c)\n",
    "                if j % 100  == 0:\n",
    "                    print('iter: %d, cost: %.3f' % (j,c))\n",
    "        plt.plot(costs)\n",
    "        plt.show()\n",
    "        \n",
    "        \n",
    "    def transform(self, X):\n",
    "        return self.sess.run(self.means,feed_dict = {self.X:X})\n",
    "    \n",
    "    def prior_predictive_with_input(self, Z):\n",
    "        return self.sess.run(\n",
    "            self.prior_predictive_from_input_probs,\n",
    "            feed_dict = {self.Z_input : Z}\n",
    "        )\n",
    "    \n",
    "    def posterior_predictive_sample(self, X):\n",
    "        # returns a sample from p(x_new | X)\n",
    "        return self.sess.run(self.posterior_predictive, feed_dict={self.X: X})\n",
    "\n",
    "    def prior_predictive_sample_with_probs(self):\n",
    "        # returns a sample from p(x_new | z), z ~ N(0, 1)\n",
    "        return self.sess.run((self.prior_predictive, self.prior_predictive_probs))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(X, epochs = 30, batch_sz = 200):\n",
    "    # convert X to binary variable,\n",
    "    # this isn't necessary\n",
    "    X = (X > 0.5).astype(np.float32)\n",
    "    \n",
    "    \n",
    "    vae = VariationalAutoencoder(784, [200, 100])\n",
    "    vae.fit(X, epochs = epochs, batch_sz = batch_sz)\n",
    "    \n",
    "    # plot reconstruction\n",
    "    done = False\n",
    "    while not done:\n",
    "        i = np.random.choice(len(X))\n",
    "        x = X[i]\n",
    "        im = vae.posterior_predictive_sample([x]).reshape(28, 28)\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.imshow(x.reshape(28, 28), cmap='gray')\n",
    "        plt.title(\"Original\")\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.imshow(im.reshape(28, 28), cmap='gray')\n",
    "        plt.title(\"Sampled\")\n",
    "        plt.show()\n",
    "        \n",
    "        ans = input(\"Generate another?\")\n",
    "        if ans and ans[0] in ('n' or 'N'):\n",
    "            done = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_batches:  110\n",
      "epochs:  0\n",
      "iter: 0, cost: -1522.228\n",
      "iter: 100, cost: -212.858\n",
      "epochs:  1\n",
      "iter: 0, cost: -203.981\n",
      "iter: 100, cost: -165.681\n",
      "epochs:  2\n",
      "iter: 0, cost: -167.786\n",
      "iter: 100, cost: -149.945\n",
      "epochs:  3\n",
      "iter: 0, cost: -152.051\n",
      "iter: 100, cost: -143.694\n",
      "epochs:  4\n",
      "iter: 0, cost: -142.268\n",
      "iter: 100, cost: -134.706\n",
      "epochs:  5\n",
      "iter: 0, cost: -137.166\n",
      "iter: 100, cost: -135.212\n",
      "epochs:  6\n",
      "iter: 0, cost: -133.337\n",
      "iter: 100, cost: -126.611\n",
      "epochs:  7\n",
      "iter: 0, cost: -127.805\n",
      "iter: 100, cost: -123.523\n",
      "epochs:  8\n",
      "iter: 0, cost: -122.834\n",
      "iter: 100, cost: -121.706\n",
      "epochs:  9\n",
      "iter: 0, cost: -118.785\n",
      "iter: 100, cost: -116.259\n",
      "epochs:  10\n",
      "iter: 0, cost: -118.103\n",
      "iter: 100, cost: -117.723\n",
      "epochs:  11\n",
      "iter: 0, cost: -118.888\n",
      "iter: 100, cost: -113.993\n",
      "epochs:  12\n",
      "iter: 0, cost: -114.976\n",
      "iter: 100, cost: -113.474\n",
      "epochs:  13\n",
      "iter: 0, cost: -113.531\n",
      "iter: 100, cost: -108.322\n",
      "epochs:  14\n",
      "iter: 0, cost: -108.333\n",
      "iter: 100, cost: -109.433\n",
      "epochs:  15\n",
      "iter: 0, cost: -107.611\n",
      "iter: 100, cost: -110.552\n",
      "epochs:  16\n",
      "iter: 0, cost: -104.721\n",
      "iter: 100, cost: -104.870\n",
      "epochs:  17\n",
      "iter: 0, cost: -107.154\n",
      "iter: 100, cost: -105.193\n",
      "epochs:  18\n",
      "iter: 0, cost: -103.514\n",
      "iter: 100, cost: -106.374\n",
      "epochs:  19\n",
      "iter: 0, cost: -102.889\n",
      "iter: 100, cost: -99.813\n",
      "epochs:  20\n",
      "iter: 0, cost: -102.351\n",
      "iter: 100, cost: -101.892\n",
      "epochs:  21\n",
      "iter: 0, cost: -102.178\n",
      "iter: 100, cost: -101.162\n",
      "epochs:  22\n",
      "iter: 0, cost: -100.238\n",
      "iter: 100, cost: -102.219\n",
      "epochs:  23\n",
      "iter: 0, cost: -100.415\n",
      "iter: 100, cost: -100.179\n",
      "epochs:  24\n",
      "iter: 0, cost: -102.917\n",
      "iter: 100, cost: -98.934\n",
      "epochs:  25\n",
      "iter: 0, cost: -97.717\n",
      "iter: 100, cost: -99.735\n",
      "epochs:  26\n",
      "iter: 0, cost: -100.107\n",
      "iter: 100, cost: -98.592\n",
      "epochs:  27\n",
      "iter: 0, cost: -98.627\n",
      "iter: 100, cost: -97.268\n",
      "epochs:  28\n",
      "iter: 0, cost: -100.054\n",
      "iter: 100, cost: -94.759\n",
      "epochs:  29\n",
      "iter: 0, cost: -96.373\n",
      "iter: 100, cost: -95.776\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate another?n\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'reshape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ff3de819b974>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_sz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m500\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-9d0d282f2190>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(X, epochs, batch_sz)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprior_predictive_sample_with_probs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m28\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcmap\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'gray'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'reshape'"
     ]
    }
   ],
   "source": [
    "main(X, epochs = 30, batch_sz=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why do the prior predictive samples generally look worse?<br>\n",
    "Perhaps no actual images mapped to the latent vector we happened to sample.<br>\n",
    "The latent vaector could also correspond to the area on the border between 2 or more different digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
